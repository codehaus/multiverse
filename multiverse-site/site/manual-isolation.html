<h1>8 Transaction isolation</h1>

<ul>
    <li><a href="#introduction">8.1 Introduction</a></li>
    <li><a href="#databases.and.isolation.levels">8.2 Databases and isolation levels</a></li>
    <li><a href="#readonly.transactions">8.5 Readonly transactions</a></li>
    <li><a href="#conflicts">8.3 Read conflicts</a>
        <ul>
            <li><a href="#read.conflicts">8.3.1 Read conflicts</a></li>
            <li><a href="#write.conflicts">8.3.2 Write conflicts</a></li>
        </ul>
    </li>
    <li><a href="#preventing.writeskew">8.6 Write skew</a></li>
    <li><a href="#liveness.problems">8.7 Liveness Problems</a>
        <ul>
            <li><a href="#deadlock">8.7.1 Deadlock</a></li>
            <li><a href="#livelock">8.7.2 Livelock</a></li>
            <li><a href="#starvation">8.7.2 Starvation</a></li>
        </ul>
    </li>
</ul>

<h2 id="introduction">8.1 Introduction</h2>
If transactions are executing concurrently, something needs to be said about how they are isolated. Multiverse
provides out of the box a near serialized isolation level, meaning that the transactions executing appears
to be behaving as executing serialized (so one after another).
<p>
    The basic rules for concurrency control:
<ol>
    <li>nothing bad happens</li>
    <li>something good happens eventually</li>
</ol>
The concurrency model used in Multiverse looks a lot like the one used in Multi Version Concurrency Control
databases like Oracle, Postgresql and MySQL+InnoDb and I'll use the Oracle terms (since they have the
most comprehensive documentation)

<h2 id="databases.and.isolation.levels">8.2 Databases and isolation levels</h2>
In traditional databases, isolation normally is defined by setting the correct isolation level on
the transaction. The isolation level describes which problems are and which allowed (essentially it is a declarative
form of concurrency control). It is up to the database to make sure that it doesn't allow more problems than
specified (of course it is allowed to cause less problems than specified).
<p>
    The following isolation levels are the standard for databases:
<ol>
    <li><b>serialized:</b> you are not allowed to observe any isolation problems. Transactions are executing
        as if they were executing one after another.
    </li>
    <li><b>repeatable-read:</b> you are allowed see a chance caused by the insert or removal of databases records,
        for example the count of set of persons could change during execution of a transaction, because a person
        was inserted or deleted by a different transaction.
    </li>
    <li><b>read-committed:</b> you are allowed to see problems allowed under the repeatable read isolation level, but
        you
        are not allowed to see uncommitted state.
    </li>
    <li><b>dirty-read:</b> you are allowed to see the see problems allowed under the read-committed isolation level
        and you are able to see uncommitted state. The big problem with dirty reads is that data could be read that
        never has become part of the database because the transaction eventually is aborted. In most cases dirty-reads
        are not a good thing and MVCC databases don't even support it.
    </li>

</ol>
Multiverse provides automatically the 'serialized' isolation level, the same isolation level MVCC databases provide.
Lower isolation levels read-dirty,read-committed and repeatable-read are not supported by the main STM implementation
in Multiverse (called the AlphaStm), so that is a
<p>
    MVCC also provide the isolation level 'readonly', that provides the same guarantees as serialized (real serialized
    even) without being able to do writes. This is exactly the same behavior you get when you set the readonly property
    of the
    TransactionalObject to true. Multiverse also provides <a href="#readonly.transactions">this isolation level</a>.
<p>
    Having such an high isolation out of the box is great if you don't want to deal with race problems, but it
    could reduce performance (and this means that transactions need to be retried more often). In the future
    we are going to provide mechanisms for overcoming these problems. Mechanisms like commuting operations or some form
    striping that can provide hints about a slot being free or filled without causing a write-conflict
    if some form of invisible read is done. Each STM instance could provide a factory for creating stripes so that
    every STM implementation can implement its own.
<p>
    Readers don't block writers and writers don't block readers. In MVCC databases it also is possible to explicit
    pessimistic
    locking by using the 'select for update' statement. This is not available atm in Multiverse, but is expected
    to be added in the future.

<h2 id="conflicts">8.3 Conflicts</h2>
There are a few types of conflicts that can happen:
<ol>
    <li><a href="#read.conflicts">read conflicts</a></li>
    <li><a href="#write.conflicts">write conflicts</a></li>
</ol>
If there are many read/write conflicts, the datastructure isn't concurrent. At the moment there is no support for
profiling to find hotspots (so find the transactions and the transactional objects that cause the problem).
But in the future this is expected.

<h3 id="read.conflicts">8.3.1 Read-conflicts</h3>
A read conflicts happens when a transaction wants to read a transactional object, that has been updated by
another transaction. Each transaction automatically receives a read version (based on a central
clock) when it starts and based on this read version the system is able to detect if certain reads
are allowed. If the system detects that the current version is newer than allowed, a read conflict is detected
and the transaction aborted and retried.
<p>
    If a field is read for the second time a few things could happen depending on the transaction configuration. If
    automatic read tracking is enabled (default this is enabled for update transaction), the transaction tracks
    all reads done by a transaction. This is not only useful for blocking operations and write skew detection,
    but it also serves as a local cache; meaning that it doesn't matter if another transaction has done an updae
    after the field has been read for the first time. A default readonly transaction does not track reads (since
    it consumes resources) but it can be activated by setting the trackReads property on the
    TransactionalMethod annotation. For more information see
    <a href="manual-mapping.html#transactionalmethod.trackReads">1
        TransactionalMethod.trackReads</a>.

<p>
    In Oracle this would be the snapshot too old exception. In the future a mechanism will be added to persist
    transactions/transactional objects and using this mechanism it is possible to read versions of objects
    that already are history. So essentially you are able to go back in time and see how the universe was;
    a perfect audit trail. In Oracle this behavior is known as 'flash back' queries.


<h3 id="write.conflicts">8.3.2 Write-conflicts </h3>
A write conflict happens when a transaction wants to write a transactional object, that has been updated by another
transaction. The write version of a transaction is determined by increasing the version of the central
clock and storing that.

<p>
    Multiverse out of the box is an object granularity stm, meaning that conflicts will be detected on the object level
    and not on the field level. This means that if an object has 2 fields, and one transaction updates one field
    and another one updates the other, these transactions can conflict. Luckily it is possible to explicitly
    configure that field granularity should be used. For more information check
    <a href="manual-mapping.html#fieldgranularity">1.6 Field Granularity</a>.
<p>
    In Oracle this problem is known under ORA-08177 (link to blog).

<h2 id="readonly.transactions">8.5 Readonly transactions</h2>


<h2 id="preventing.writeskew">8.6 Write skew</h2>
Multiverse automatically uses a near serialized isolation level (exactly the same as the Oracle serialized isolation
level). It isn't perfect however because there is one anomaly that can happen;
<a href="http://en.wikipedia.org/wiki/Snapshot_isolation">the write skew</a>

TODO: explain writeskew.

<p>
    In Multiverse the writeSkew problem can be prevented by setting the writeSkew parameter (defaults to true).
<pre>
    @TransactionalMethod(writeSkew = true, trackReads = true)
    void transfer(Account from1, Account from2, Account to, int amount){
        if(from1.get()+from2.get()&lt;amount){
            throw new NotEnoughMoneyException();
        }

        from1.dec(amount);
        to.inc(amount);
    }
</pre>
Write skew detection relies on automatic readtracking since all read transactional objects, need to be re-checked.
<p>
    In MVCC databases like Oracle it isn't possible to get prevention against writeskew as direct feature, so one of
    the things you can do is use a select for update so that the record automatically is locked, or
<p>
    So this
    means that there are certain cenario's that an MVCC database allow for concurrent executions that violates
    with any serialized execution of transactions.

<h2 id="Partial ordering and the clock">Version and ordering</h2>
Multiverse is based on the TL2 design made by David Dice (....) and can be found here. TL2 implementations
centrally have a single shared components; clock (could be based on an AtomicLock). Based on this clock the
transaction is able to figure out of it does anything illegal while doing read or writes.
<p>
    The ordering of transactions is partial, only when there is shared state anything can be said about the order
    or transactions committing. So this means that nothing needs to be set about transactions executing concurrently
    if they don't share state. On a lower level it could mean that a transaction is interleaves after
    it increased the clock but before it actually commits. If that transaction has the chance to
    finishes sooner, it received a higher version of the clock it increased but does the actual
    writes before the first transaction begins doing the writes.
<p>
    This can can be hard stuff to swallow, but from a practical point of view it means that a version assigned to
    tranlocals <b>can't</b>> be used as absolute indicate of the order the commits were done.
    So be careful what that.

<h3>Clock as scalability bottleneck</h3>
The clock needed for TL2 implementation causes contention on the memory bus, even between transactions (especially
between update transactions) that don't share any state, so eventually it will become a bottleneck. Removing the
clock will get a high attention in the future when are going to scale up to more and more cores. But on my dual
cpu xeon systems (8 real processors in total, or 16 virtual ones with hyperthreading enabled) I'm able to
do 15M updates on the clock a second. So in theory that would mean the same amount of update transactions and
even a higher amount of readonly transactions a second.

<h2 id="liveness.problems">Liveness Problems</h2>


<h3 id="deadlocks">Deadlocks</h3>
Multiverse protects against <a href="http://en.wikipedia.org/wiki/Deadlock">deadlocks</a>. Multiverse doesn't rely on
pessimistic locks as the main lock implementation.
Most of the locks are optimistic, only when the commit is done for a very short amount of time pessimistic
locks are acquired. Since pessimistic locks are not hold indefinitely (if a transaction can't acquire the locks
it fails.. is configurable through a commitlockpolicy), a transaction can't deadlock.

<h3 id="starvation">Starvation</h3>
<a href="http://en.wikipedia.org/wiki/Resource_starvation">Starvation</a> is the situation where one of the processes
can't make any progress, because it isn't granted the resources
needed to make progress, e.g. it wants to make changes on a transactional objects, but every time it wants to
commit, the transaction aborts..

<h3 id="livelock">Livelock</h3>
A <a href="http://en.wikipedia.org/wiki/Livelock#Livelock">Livelock</a> happens when transactions try to execute
but are not able to complete. So from the outside it looks
like the system is working (using memory and cpu cycles) but it isn't making any progress. It can happen that
a transaction can't commit because:
<ol>
    <li>read conflict</li>
    <li>write conflict</li>
</ol>
To prevent livelocks, default all transactions have a maxRetries of 1000. This is combined with a retrypolicy,
(default a bounded exponential backoff policy is used with a 10ms max delay.. although that doesn't say much
since most operating systems provide no real time guarantees).